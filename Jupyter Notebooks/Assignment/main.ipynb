{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Fashion MNSIT dataset, get a accuracy of at least .8\n",
    "\n",
    "Build a Neural Network from scratch and tune the hyperparameters to get an accuracy of at least 80% or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Fashion MNSIT dataset\n",
    "\n",
    "(trainImages, trainLabels), (testImages, testLabels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Labels names and their indexes\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Class names\n",
    "\n",
    "classNames = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Exploring the Training Dataset\n",
    "print(\"Training Dataset shape: \", trainImages.shape)\n",
    "\n",
    "# Training Dataset Labels\n",
    "print(\"Dataset Lables: \", trainLabels)\n",
    "print(\"Labels Length: \", len(trainLabels))\n",
    "\n",
    "# Exploring the Testing Dataset\n",
    "print(\"Testing Dataset shape: \", testImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Data\n",
    "\n",
    "_index = 1000 # 59999 is the Max Index\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(trainImages[_index])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Image Pixel value from 0-255 to 0-1\n",
    "\n",
    "trainImages = trainImages / 255.0\n",
    "testImages = testImages / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the format of the data and plotting it\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainImages[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(classNames[trainLabels[i]])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding the training and testing dataset\n",
    "\n",
    "def one_hit_encode(outputLayerLength, dataLabel):\n",
    "    return np.eye(dataLabel)[outputLayerLength]\n",
    "\n",
    "encodedTrainImages = one_hit_encode(trainLabels, len(classNames))\n",
    "encodedTestImages = one_hit_encode(trainLabels, len(classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network Definition\n",
    "\n",
    "class NeuralNetwork:\n",
    "     def __init__(self, inputSize, hiddenSize, outputSize, learnRate=0.01, lambdaL1=0.0, lambdaL2=0.0):\n",
    "         # Weights and Biases of the connection between first [0] and second [1] layer\n",
    "         self.W1 = np.random.randn(inputSize, hiddenSize) * 0.01\n",
    "         self.b1 = np.zeros((1, hiddenSize))\n",
    "         \n",
    "         # Weights and Biases of the connection between second [1] and third [2] layer\n",
    "         self.W2 = np.random.randn(hiddenSize, outputSize) * 0.01\n",
    "         self.b2 = np.zeros((1, outputSize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
