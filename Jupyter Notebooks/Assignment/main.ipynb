{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Fashion MNSIT dataset, get a accuracy of at least .8\n",
    "\n",
    "Build a Neural Network from scratch and tune the hyperparameters to get an accuracy of at least 80% or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Fashion MNSIT dataset\n",
    "(trainImages, trainLabels), (testImages, testLabels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Labels names and their indexes\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Class names\n",
    "\n",
    "classNames = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Exploring the Training Dataset\n",
    "print(\"Training Dataset shape: \", trainImages.shape)\n",
    "\n",
    "# Training Dataset Labels\n",
    "print(\"Dataset Lables: \", trainLabels)\n",
    "print(\"Labels Length: \", len(trainLabels))\n",
    "\n",
    "# Exploring the Testing Dataset\n",
    "print(\"Testing Dataset shape: \", testImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Data\n",
    "\n",
    "_index = 1000 # 59999 is the Max Index\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(trainImages[_index])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the format of the data and plotting it\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainImages[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(classNames[trainLabels[i]])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the Training Images and Testing Images\n",
    "trainImages = trainImages.reshape(trainImages.shape[0], -1) / 255.0\n",
    "testImages = testImages.reshape(testImages.shape[0], -1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding the training and testing dataset\n",
    "\n",
    "def one_hit_encode(outputLayerLength, dataLabel):\n",
    "    return np.eye(dataLabel)[outputLayerLength]\n",
    "\n",
    "trainLabelsEncoded = one_hit_encode(trainLabels, len(classNames))\n",
    "testLabelEncoded = one_hit_encode(testLabels, len(classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network Definition\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, learnRate=0.01, lambdaL1=0.0, lambdaL2=0.0):\n",
    "         # Weights and Biases of the connection between first [0] and second [1] layer\n",
    "         self.W1 = np.random.randn(inputSize, hiddenSize) * 0.01\n",
    "         self.b1 = np.zeros((1, hiddenSize))\n",
    "         \n",
    "         # Weights and Biases of the connection between second [1] and third [2] layer\n",
    "         self.W2 = np.random.randn(hiddenSize, outputSize) * 0.01\n",
    "         self.b2 = np.zeros((1, outputSize))\n",
    "         \n",
    "         # Learning Rate to decrease error\n",
    "         self.learnRate = learnRate\n",
    "         \n",
    "         # Regularizations through lambdas\n",
    "         self.lambdal1 = lambdaL1\n",
    "         self.lambdal2 = lambdaL2\n",
    "        \n",
    "    # axis=1 -- Ensures the operation is being done in row-wise, i.e, only one one axis\n",
    "    # keepdims=Ture -- Ensures the output array is the same size as the input array\n",
    "        \n",
    "    def SoftMax(self, trainData):\n",
    "        ePowerZi = np.exp(trainData - np.max(trainData, axis=1, keepdims=True))       # Subtracting the max to ensure the maximum limit of the exponent is (e^0 = 1)\n",
    "        return ePowerZi / np.sum(ePowerZi, axis=1, keepdims=True)\n",
    "    \n",
    "    def ForwardPropogation(self, trainData):\n",
    "        # The Linear Combination of the Weights and Biases for Hidden Layer -- np.dot() - Matrix Multiplcation\n",
    "        self.Z1 = np.dot(trainData, self.W1) + self.b1\n",
    "        self.A1 = np.tanh(self.Z1) # Plugging in the Activation function\n",
    "        \n",
    "        # The Linear Combination of the Weights and Biases for Output Layer -- np.dot() - Matrix Multiplcation\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.SoftMax(self.Z2)\n",
    "        \n",
    "        return self.A2\n",
    "        \n",
    "    def BackwardPropogation(self, trainData, labelData, predictionData):\n",
    "        trainDataSize = trainData.shape[0]  # The Training Dataset size\n",
    "        \n",
    "        outputError = predictionData - labelData\n",
    "        hiddenError = np.dot(outputError, self.W2.T) * (1 - np.tanh(self.Z1) ** 2)\n",
    "        \n",
    "        dW2 = np.dot(self.A1.T, outputError) / trainDataSize    # Derivative of the Weights as a Average\n",
    "        db2 = np.sum(outputError, axis=0, keepdims=True) / trainDataSize\n",
    "\n",
    "        dW1 = np.dot(trainData.T, hiddenError) / trainDataSize\n",
    "        db1 = np.sum(hiddenError, axis=0, keepdims=True) / trainDataSize\n",
    "        \n",
    "        # L1 Regularization\n",
    "        dW1 += self.lambdal1 * np.sign(self.W1)\n",
    "        dW2 += self.lambdal1 * np.sign(self.W2)\n",
    "                \n",
    "        # L2 Regularization\n",
    "        dW1 += self.lambdal2 * self.W1\n",
    "        dW2 += self.lambdal2 * self.W2\n",
    "        \n",
    "        # Implying the Error contributions to the weights and biases\n",
    "        \n",
    "        self.W1 -= self.learnRate * dW1\n",
    "        self.b1 -= self.learnRate * db1\n",
    "        \n",
    "        self.W2 -= self.learnRate * dW2\n",
    "        self.b2 -= self.learnRate * db2\n",
    "        \n",
    "    def TrainModel(self, trainData, labelData, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            prediction = self.ForwardPropogation(trainData)     # Performing the Forward Propogation for the Model\n",
    "            self.BackwardPropogation(trainData, labelData, prediction)      # Performing the Backward Propogation for the Weights and Biases\n",
    "            \n",
    "            if(epoch % 1000 == 0):\n",
    "                loss = -np.mean(np.sum(labelData * np.log(prediction + 1e-10), axis=1))\n",
    "                print(f\"Epoch: {epoch}, Loss: {loss: .4f}\")     # Printing the Loss Value for every 100 Epochs\n",
    "                \n",
    "    def Predict(self, trainData):\n",
    "        prediction = self.ForwardPropogation(trainData)\n",
    "        return np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hyperparameters\n",
    "\n",
    "inputSize = 28*28   # The Number of Input Neurons -- Here it is 28*28, Because of the number of pixels\n",
    "hiddenSize = 512    # The Number of the Hidden Neurons\n",
    "outputSize = len(classNames)     # The Number of possible outputs -- Here it is the length of the number of classes of clothing\n",
    "learnRate = 0.1     # The amount by which the error may decrease\n",
    "\n",
    "# Regularization\n",
    "l1 = 0.0001\n",
    "l2 = 0.001\n",
    "\n",
    "epochs = 25000      # The Number of generations that the model will go through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now actually defining a object of the Neural Network\n",
    "\n",
    "This will actually train the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Neural Network Model Object\n",
    "neuralNetworkModel = NeuralNetwork(inputSize, hiddenSize, outputSize, learnRate, l1, l2)\n",
    "neuralNetworkModel.TrainModel(trainImages, trainLabelsEncoded, epochs)\n",
    "\n",
    "# Checking Accuracy of the Predictions\n",
    "finalPredicition = neuralNetworkModel.Predict(testImages)\n",
    "accuracy = np.mean(finalPredicition == testLabels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
